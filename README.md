# Generative AI with Large Language Models (LLMs)

Welcome to the Generative AI with Large Language Models (LLMs) repository! In this course, you'll dive into the exciting world of generative AI and learn how to deploy it in real-world applications.

## Course Overview

In this course, you will:

- Gain a deep understanding of generative AI and its key components within the lifecycle of LLM-based generative AI projects, from data collection to deployment.
- Explore the powerful transformer architecture that drives LLMs, including their training process and how fine-tuning enables adaptation to specific use cases.
- Apply empirical scaling laws to optimize the model's performance across various factors such as dataset size, computation resources, and inference needs.
- Utilize cutting-edge techniques for training, tuning, inference, tools, and deployment to maximize model performance within project constraints.
- Engage in discussions about the challenges and opportunities that generative AI brings to businesses, guided by insights from industry researchers and practitioners.

## Learning Objectives

Week 1:
- Understand the distinction between model pre-training and fine-tuning.
- Define terms like Generative AI, large language models, and the transformer architecture that powers LLMs.
- Learn about the lifecycle of an LLM-based generative AI model and the decisions made at each step.
- Explore methods to reduce memory footprint during model pre-training.
- Discover scaling laws that guide training dataset size, computation budget, and inference requirements.

Week 2:
- Dive into fine-tuning LLMs using prompt datasets and instructions.
- Explore techniques to overcome challenges like catastrophic forgetting during fine-tuning.
- Learn about Parameter-efficient Fine Tuning (PEFT) and its benefits.
- Understand the impact of fine-tuning with instructions on LLM performance.

Week 3:
- Explore how Reinforcement Learning from Human Feedback (RLHF) improves LLM performance.
- Understand the role of human labelers and reward models in RLHF.
- Discover chain-of-thought prompting and its enhancement of LLM reasoning abilities.
- Learn about challenges in LLMs related to knowledge cut-offs and how augmentation techniques address them.

## Labs and Quizzes

Throughout the course, you'll engage with practical labs and quizzes to reinforce your understanding and hands-on skills. From exploring generative AI use cases to fine-tuning models and applying reinforcement learning, you'll gain valuable experience in deploying LLMs.

We're excited to embark on this journey into Generative AI with you. Let's dive in and explore the incredible capabilities of Large Language Models!
